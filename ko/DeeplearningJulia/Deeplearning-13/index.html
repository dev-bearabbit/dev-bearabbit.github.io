

<!DOCTYPE html>
<html lang="ko" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="alternate" hreflang="ko" href="https://dev-bearabbit.github.io/" />
  <link rel="alternate" hreflang="en" href="https://dev-bearabbit.github.io/en/" />  
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" href="/img/favicon.ico">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#000">
  <meta name="author" content="Jess">
  <meta name="keywords" content="">
  
    <meta name="description" content="해당 시리즈는 프로그래밍 언어 중 하나인 줄리아(Julia)로 딥러닝(Deep learning)을 구현하면서 원리를 설명합니다.">
<meta property="og:type" content="article">
<meta property="og:title" content="[Deep Learning in Julia] 인공신경망 최적화: 드랍아웃 (13&#x2F;18)">
<meta property="og:url" content="https://dev-bearabbit.github.io/ko/DeeplearningJulia/Deeplearning-13/index.html">
<meta property="og:site_name" content="DEV AnythinG">
<meta property="og:description" content="해당 시리즈는 프로그래밍 언어 중 하나인 줄리아(Julia)로 딥러닝(Deep learning)을 구현하면서 원리를 설명합니다.">
<meta property="og:locale" content="ko_KR">
<meta property="og:image" content="https://dev-bearabbit.github.io/images/63.png">
<meta property="og:image" content="https://dev-bearabbit.github.io/images/64.png">
<meta property="article:published_time" content="2020-06-14T06:07:18.000Z">
<meta property="article:modified_time" content="2025-01-27T20:28:10.962Z">
<meta property="article:author" content="Jess">
<meta property="article:tag" content="딥러닝">
<meta property="article:tag" content="Deeplearning">
<meta property="article:tag" content="머신러닝">
<meta property="article:tag" content="줄리아">
<meta property="article:tag" content="신경망">
<meta property="article:tag" content="Dropout">
<meta property="article:tag" content="드랍아웃">
<meta property="article:tag" content="MLP">
<meta property="article:tag" content="뉴럴네트워크">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://dev-bearabbit.github.io/images/63.png">
  
  
  
  <title>[Deep Learning in Julia] 인공신경망 최적화: 드랍아웃 (13/18) - DEV AnythinG</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"dev-bearabbit.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":"G-QW3E4LZZNF"},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=G-QW3E4LZZNF", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', 'G-QW3E4LZZNF');
        });
      }
    </script>
  

  

  

  



  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>DEV AnythinG</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="javascript:;" id="languageDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
            <i class="iconfont icon-globe"></i> <span id="current-lang"></span>
          </a>
          <div class="dropdown-menu" aria-labelledby="languageDropdown">
            <a class="dropdown-item" href="/">한국어</a>
            <a class="dropdown-item" href="/en/">English</a>
          </div>
        </li>
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

<script>
  document.addEventListener('DOMContentLoaded', () => {
    // 현재 언어를 URL 기반으로 감지
    const path = window.location.pathname;
    const currentLang = path.startsWith('/en/') ? 'English' : '한국어';

    // 선택된 언어를 버튼에 표시
    const currentLangElement = document.getElementById('current-lang');
    currentLangElement.textContent = currentLang;
  });
</script>

  

<div id="banner" class="banner" parallax=true
  style="background: url('/img/background.gif') no-repeat center center; background-size: cover;">
  <canvas id="canvas" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></canvas>
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="[Deep Learning in Julia] 인공신경망 최적화: 드랍아웃 (13/18)"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2020-06-14 15:07" pubdate>
          2020년 6월 14일 오후
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          715 words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          6 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', () => {
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    // 캔버스 크기를 배너 크기와 동기화
    const banner = document.getElementById('banner');
    canvas.width = banner.offsetWidth;
    canvas.height = banner.offsetHeight;

    const cols = Math.floor(canvas.width / 20) + 1;
    const ypos = Array(cols).fill(0);

    function matrix() {
      ctx.fillStyle = '#0001'; // 배경 페이드 효과
      ctx.fillRect(0, 0, canvas.width, canvas.height);

      ctx.fillStyle = '#009600'; // 텍스트 색상
      ctx.font = '14pt monospace';

      ypos.forEach((y, index) => {
        const text = String.fromCharCode(33 + Math.random() * 94); // 랜덤 ASCII 문자
        const x = index * 20;
        ctx.fillText(text, x, y);

        if (y > canvas.height + Math.random() * 10000) ypos[index] = 0;
        else ypos[index] = y + 20;
      });
    }

    setInterval(matrix, 60);

    // 창 크기 조정 시 캔버스 크기 업데이트
    window.addEventListener('resize', () => {
      canvas.width = banner.offsetWidth;
      canvas.height = banner.offsetHeight;
    });
  });
</script>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">[Deep Learning in Julia] 인공신경망 최적화: 드랍아웃 (13/18)</h1>
            
            
              <div class="markdown-body">
                
                <p>해당 시리즈는 프로그래밍 언어 중 하나인 줄리아(Julia)로 딥러닝(Deep learning)을 구현하면서 원리를 설명합니다. <span id="more"></span></p>
<hr />
<h2 id="드랍아웃dropout이란">드랍아웃(Dropout)이란</h2>
<p>드랍아웃은 인공신경망 훈련 과정을 최적화하기 위한 방법 중 하나이며, 오버피팅(overfitting)을 방지함으로써 모델의 정확도를 높여준다.</p>
<p><strong>Note</strong> 오버피팅(overfitting)이란? 신경망을 학습하는 과정에서 훈련데이터에만 적합한 형태로 학습되는 현상을 오버피팅이라고 한다. 훈련데이터의 정확도는 거의 100%를 달성하는데 실제데이터에서는 일정 이상의 정확도에서 상승하지 않는 것이다. 이런 현상은 보통 훈련데이터를 너무 적게 사용한 경우 또는 모델 파라미터가 너무 많은 경우에 발생한다.</p>
<p>드랍아웃은 각각의 훈련데이터들이 결과값으로 연결되는 신호(엣지, Edge)를 일정한 퍼센트로 삭제함으로써 훈련데이터의 일부만 파라미터에 영향을 줄 수 있도록 조정하는 역할을 한다. 드랍아웃을 함수로 만들면 다음과 같다.</p>
<h2 id="드랍아웃-구현">드랍아웃 구현</h2>
<p>드랍아웃은 입력된 비율에 따라 몇몇의 신호값들을 0으로 반환한다. 이를 함수로 구현하면 다음과 같다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs Julia"><span class="hljs-keyword">using</span> Random<br><br><span class="hljs-keyword">function</span> drop_out_single(input_size, rate)<br>    <span class="hljs-keyword">function</span> changing_T_or_F_with_percentage(number, input_size, rate)<br>        temp_num = input_size * rate<br>        <span class="hljs-keyword">if</span> number &gt; temp_num<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>        <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">end</span><br>    temp = shuffle(reshape(<span class="hljs-number">1</span>:input_size, <span class="hljs-number">1</span>, input_size))<br>    <span class="hljs-keyword">return</span> changing_T_or_F_with_percentage.(temp, input_size, rate)<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>
<p>위 함수는 신호값과 곱하는 마스크를 생성한다. 드랍아웃에서는 비율을 입력값으로 받아 입력된 신호값의 일부 위치를 무작위로 선정하고, 그 자리의 신호를 0으로 반환해야 하는데 이를 구현하기 위해 기술적으로 신호값과 곱해주는 마스크를 생성하는 것이다. 하지만 이는 데이터 하나의 형태(한 줄)에만 작동하는 함수이다. 우리는 지금까지 배치데이터(여러 줄)를 사용해왔기 때문에 각각의 모든 줄에 위의 드랍아웃을 적용하는 함수가 필요하다.</p>
<p><strong>Note</strong> 배치데이터에서 드랍아웃의 작동원리 드랍아웃은 각각의 데이터들이 동일한 비율로 신호값이 제거되어야 한다. 다시 말해, 한 줄로 나열된 데이터를 여러 개 합쳐놓은 매트릭스 형태의 배치데이터에서는 한 줄마다 일정한 비율을 유지해주면서 신호값을 제거해야 한다. 그렇기에 한 줄씩 인덱스를 무작위로 선정하여 제거해주는 작업이 필수적이다. 만약 이를 고려하지 않고 배치데이터를 드랍아웃한다면, 이는 효과가 거의 없다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs Julia"><span class="hljs-keyword">function</span> drop_out(input_size, hidden_size, rate)<br>    temp = drop_out_single(hidden_size, rate)<br>    temp_num = input_size - <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> i = <span class="hljs-number">1</span>:temp_num<br>        temp_1 = drop_out_single(hidden_size, rate)<br>        temp = [temp; temp_1]<br>    <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">return</span> temp<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>
<p>위 함수는 <code>drop_out_single()</code>을 배치데이터에 사용할 수 있도록 변환한 것이다. 위 함수에서 사용된 <code>input_size</code>와 <code>hidden_size</code>는 배치데이터에서 행렬의 형상이다. 예를 들어 입력된 신호값이 <span class="math inline">\(10 \times 784\)</span>의 행렬이라면 이는 <span class="math inline">\(1 \times 784\)</span> 데이터가 총 10개가 포함된 배치데이터이기에 <code>drop_out_single()</code>을 <code>input_size</code>만큼 반복하는 것이다.</p>
<p>신호값과 곱해줄 드랍아웃 마스크는 완성되었다. 이제는 신호값과 마스크를 곱해주는 함수를 생성해보자. 참고로 드랍아웃도 신호값을 제거하는 과정이기에 이후 역전파에서 같은 위치의 미분값이 제거되어야 한다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs Julia"><span class="hljs-keyword">mutable struct</span> Dropout<br>    mask<br><span class="hljs-keyword">end</span><br><br><span class="hljs-keyword">function</span> dropout_forward(dropout, x, dropout_ratio)<br>    <span class="hljs-keyword">if</span> dropout_ratio &lt; <span class="hljs-number">1</span><br>        dropout.mask = drop_out(size(x)[<span class="hljs-number">1</span>],size(x)[<span class="hljs-number">2</span>], dropout_ratio)<br>        <span class="hljs-keyword">return</span> x .* dropout.mask<br>    <span class="hljs-keyword">else</span> dropout_ratio = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">return</span> x .*  (<span class="hljs-number">1.0</span> - dropout_ratio)<br>        <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br><br><span class="hljs-keyword">function</span> dropout_backward(dropout, dout)<br>    <span class="hljs-keyword">return</span> dout .* dropout.mask<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>
<p>이제 드랍아웃을 위한 함수 구현은 모두 끝났다. 다음으로는 위 함수들을 이용하여 드랍아웃을 적용한 모델과 적용하지 않은 모델을 비교해보자.</p>
<h2 id="신경망-모델-구현">신경망 모델 구현</h2>
<p>신경망 모델은 지금까지 구현했던 <code>MNIST</code>데이터를 사용하는 2층 신경망 모델을 다시 사용할 것이다. 역전파 모델에 대한 정보는 <a href="https://dev-bearabbit.github.io/2020/04/20/DeeplearningJulia/Deeplearning-9/">해당 글</a>에서 확인할 수 있다. 또한 모델 구성에 필요한 함수들은 <a target="_blank" rel="noopener" href="https://github.com/Hyeonji-Ryu/Deep_Learning_in_Julia/blob/master/MLP/train_forward_propagation.jl">깃허브</a>에서 찾아볼 수 있다. 준비가 완료되었다면 본격적으로 구현해보자.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs Julia"><span class="hljs-comment">#훈련데이터 300개</span><br><br>train_x = train_x[<span class="hljs-number">1</span>:<span class="hljs-number">300</span>,:]<br>train_y = train_y[<span class="hljs-number">1</span>:<span class="hljs-number">300</span>,:]<br>t = t[<span class="hljs-number">1</span>:<span class="hljs-number">300</span>,:]<br></code></pre></td></tr></table></figure>
<p>이번 구현에서는 오버피팅을 발생시키기 위해서 60000개인 <code>train_x</code>데이터 중에서 300개만을 사용하여 학습시킬 것이다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs Julia">params = <span class="hljs-built_in">Dict</span>()<br>grads = <span class="hljs-built_in">Dict</span>()<br><br><span class="hljs-comment"># 층에 들어갈 가중치와 편향 입력</span><br>W = [<span class="hljs-string">&quot;W1&quot;</span>, <span class="hljs-string">&quot;W2&quot;</span>]<br>b = [<span class="hljs-string">&quot;b1&quot;</span>, <span class="hljs-string">&quot;b2&quot;</span>]<br>hidden_size = [<span class="hljs-number">50</span>]<br><br>making_network(W,b,<span class="hljs-number">784</span>,hidden_size,<span class="hljs-number">10</span>,<span class="hljs-string">&quot;std&quot;</span>)<br><br><span class="hljs-comment"># 계층마다 인스턴스를 만들어줘야 한다. (for 역전파)</span><br><br>result = SoftmaxwithLoss(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br>dense1 = dense_layer(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br>dense2 = dense_layer(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br>Sigmoid1 = Sigmoid(<span class="hljs-number">0</span>)<br>Relu = ReLu(<span class="hljs-number">0</span>)<br>optimizer = optimizers(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br><br><br>accuracy_test = <span class="hljs-built_in">Float64</span>[]<br>accuracy_train = <span class="hljs-built_in">Float64</span>[]<br>train_size = size(train_x)[<span class="hljs-number">1</span>]<br>batch_size = <span class="hljs-number">100</span><br>learning_rate = <span class="hljs-number">0.01</span><br></code></pre></td></tr></table></figure>
<p>모델 학습을 위한 변수들을 정의한다. 참고로 여기서 사용된 <code>making_network()</code>는 이전글인 <a href="https://dev-bearabbit.github.io/2020/05/15/DeeplearningJulia/Deeplearning-12/">가중치 초기값</a>에서 사용했던 함수와 다르다. 역전파 알고리즘에서 사용했던 함수와 동일하다. 만약 새로운 <code>making_network()</code>를 사용하고 싶다면, 가중치와 편향 입력 부분을 아래와 같이 변경하면 된다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Julia"><span class="hljs-comment"># 층에 들어갈 가중치와 편향 입력</span><br>W = [<span class="hljs-string">&quot;W1&quot;</span>, <span class="hljs-string">&quot;W2&quot;</span>]<br>b = [<span class="hljs-string">&quot;b1&quot;</span>, <span class="hljs-string">&quot;b2&quot;</span>]<br>input_size = (<span class="hljs-number">1</span>, <span class="hljs-number">784</span>)<br>hidden_size = [(<span class="hljs-number">784</span>,<span class="hljs-number">50</span>),(<span class="hljs-number">50</span>,<span class="hljs-number">10</span>)]<br><br>params = making_network(W, b, weight_size, input_size, <span class="hljs-string">&quot;std&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>이제 모델을 작동시킬 준비가 끝났다. 아래의 코드를 입력하여 학습을 시작하자.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs Julia"><span class="hljs-meta">@time</span> <span class="hljs-keyword">begin</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">6000</span><br>        batch_mask = rand(<span class="hljs-number">1</span>:<span class="hljs-number">300</span>, <span class="hljs-number">100</span>)<br>        x_batch = train_x[batch_mask, :]<br>        t_batch = t[batch_mask, :]<br><br>        <span class="hljs-comment"># 순전파</span><br>        z1 = dense_layer_forward(dense1,x_batch,params[<span class="hljs-string">&quot;W1&quot;</span>],params[<span class="hljs-string">&quot;b1&quot;</span>])<br>        a1 = relu_forward(Relu,z1)<br>        z2 = dense_layer_forward(dense2,a1,params[<span class="hljs-string">&quot;W2&quot;</span>],params[<span class="hljs-string">&quot;b2&quot;</span>])<br>        num = SoftmaxwithLoss_forward(z2,t_batch)<br><br>        <span class="hljs-comment"># 역전파</span><br>        last_layer = SoftmaxwithLoss_backward(result)<br>        z2_back = dense_layer_backward(dense2, last_layer)<br>        grads[<span class="hljs-string">&quot;W2&quot;</span>] = dense2.dw<br>        grads[<span class="hljs-string">&quot;b2&quot;</span>] = dense2.db<br>        a1_back = relu_backward(Relu,z2_back)<br>        z1_back = dense_layer_backward(dense1, a1_back)<br>        grads[<span class="hljs-string">&quot;W1&quot;</span>] = dense1.dw<br>        grads[<span class="hljs-string">&quot;b1&quot;</span>] = dense1.db<br><br>        <span class="hljs-comment">#가중치 갱신</span><br>        SGD(params, grads)<br><br>        temp_loss = loss(x_batch, t_batch)<br>        print(<span class="hljs-string">&quot;NO.<span class="hljs-variable">$i</span>: &quot;</span>)<br>        println(temp_loss)<br>        append!(train_loss_list, temp_loss)<br>        append!(accuracy_test, evaluate(test_x, test_y))<br>        append!(accuracy_train, evaluate(train_x, train_y))<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>
<p>위 모델은 300개의 데이터를 100개 배치데이터 단위로 2000에폭 학습한다. 이제 위의 결과를 그래프를 그려 확인해보자.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Julia">without_train = vcat(accuracy_train)<br>without_test = vcat(accuracy_test)<br><br>x = range(<span class="hljs-number">1</span>,length(without_train),step=<span class="hljs-number">1</span>)<br>data = [without_train without_test]<br>labels = [<span class="hljs-string">&quot;accuracy_train&quot;</span> <span class="hljs-string">&quot;accuracy_test&quot;</span>]<br>markercolors = [<br>    :red :blue<br>]<br><br>pl_nodrop=plot(<br>    x,<br>    data,<br>    label = labels,<br>    color = markercolors,<br>    markersize = <span class="hljs-number">4</span>,<br>    title = <span class="hljs-string">&quot;Accuracy without Dropout&quot;</span><br>)<br></code></pre></td></tr></table></figure>
<p>그 결과는 아래와 같다.</p>
<figure>
<img src="/images/63.png" srcset="/img/loading.gif" lazyload alt="드랍아웃 없음" /><figcaption aria-hidden="true">드랍아웃 없음</figcaption>
</figure>
<p>그래프를 확인해보면 훈련데이터는 정확도가 거의 100%에 가깝지만 실제데이터의 정확도는 80% 근방에서 멈춘 것을 확인할 수 있다. 따라서 이런 경우 드랍아웃을 추가하면 위의 현상을 완화시킬 수 있다. 이제 드랍아웃이 적용된 모델을 확인하자.</p>
<p><strong>WARNING</strong> 모델을 다시 훈련시키기에 앞서 가중치와 편향을 다시 초기화해주어야 한다. 따라서 다시 아래의 코드를 작동시켜야 한다.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs Julia">params = <span class="hljs-built_in">Dict</span>()<br>grads = <span class="hljs-built_in">Dict</span>()<br><br><span class="hljs-comment"># 층에 들어갈 가중치와 편향 입력</span><br>W = [<span class="hljs-string">&quot;W1&quot;</span>, <span class="hljs-string">&quot;W2&quot;</span>]<br>b = [<span class="hljs-string">&quot;b1&quot;</span>, <span class="hljs-string">&quot;b2&quot;</span>]<br>hidden_size = [<span class="hljs-number">50</span>]<br><br>making_network(W,b,<span class="hljs-number">784</span>,hidden_size,<span class="hljs-number">10</span>,<span class="hljs-string">&quot;std&quot;</span>)<br><br><span class="hljs-comment"># 계층마다 인스턴스를 만들어줘야 한다. (for 역전파)</span><br><br>result = SoftmaxwithLoss(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br>dense1 = dense_layer(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br>dense2 = dense_layer(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br>Sigmoid1 = Sigmoid(<span class="hljs-number">0</span>)<br>Relu = ReLu(<span class="hljs-number">0</span>)<br>optimizer = optimizers(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>)<br><br><br>accuracy_test = <span class="hljs-built_in">Float64</span>[]<br>accuracy_train = <span class="hljs-built_in">Float64</span>[]<br>train_size = size(train_x)[<span class="hljs-number">1</span>]<br>batch_size = <span class="hljs-number">100</span><br>learning_rate = <span class="hljs-number">0.01</span><br></code></pre></td></tr></table></figure>
<p>이제 모델을 학습해보자.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs Julia"><span class="hljs-meta">@time</span> <span class="hljs-keyword">begin</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-number">1</span>:<span class="hljs-number">6000</span><br>        batch_mask = rand(<span class="hljs-number">1</span>:<span class="hljs-number">300</span>, <span class="hljs-number">100</span>)<br>        x_batch = train_x[batch_mask, :]<br>        t_batch = t[batch_mask, :]<br><br>        <span class="hljs-comment"># 신경망 계산</span><br>        z1 = dense_layer_forward(dense1,x_batch,params[<span class="hljs-string">&quot;W1&quot;</span>],params[<span class="hljs-string">&quot;b1&quot;</span>])<br>        a1 = relu_forward(Relu,z1)<br>        dt = dropout_forward(dropout, a1, <span class="hljs-number">0.3</span>) <span class="hljs-comment"># 드랍아웃 레이어</span><br>        z2 = dense_layer_forward(dense2,dt,params[<span class="hljs-string">&quot;W2&quot;</span>],params[<span class="hljs-string">&quot;b2&quot;</span>])<br>        num = SoftmaxwithLoss_forward(z2,t_batch)<br><br>        <span class="hljs-comment"># 역전파</span><br>        last_layer = SoftmaxwithLoss_backward(result)<br>        z2_back = dense_layer_backward(dense2, last_layer)<br>        grads[<span class="hljs-string">&quot;W2&quot;</span>] = dense2.dw<br>        grads[<span class="hljs-string">&quot;b2&quot;</span>] = dense2.db<br>        dt_back = dropout_backward(dropout,z2_back) <span class="hljs-comment"># 드랍아웃 레이어</span><br>        a1_back = relu_backward(Relu, dt_back)<br>        z1_back = dense_layer_backward(dense1, a1_back)<br>        grads[<span class="hljs-string">&quot;W1&quot;</span>] = dense1.dw<br>        grads[<span class="hljs-string">&quot;b1&quot;</span>] = dense1.db<br><br>        <span class="hljs-comment">#가중치 갱신</span><br>        SGD(params, grads)<br><br>        temp_loss = loss(x_batch, t_batch)<br>        print(<span class="hljs-string">&quot;NO.<span class="hljs-variable">$i</span>: &quot;</span>)<br>        println(temp_loss)<br>        append!(train_loss_list, temp_loss)<br>        append!(accuracy_test, evaluate(test_x, test_y))<br>        append!(accuracy_train, evaluate(train_x, train_y))<br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>
<p>위 모델은 중간에 드랍아웃이 적용되어 있다. 드랍아웃 레이어를 확인해보면 비율 파라미터 자리에 <code>0.3</code>이 있다. 즉, 30%의 신호값을 제거하라는 의미이다. 이제 위의 결과를 그래프를 그려 확인해보자.</p>
<figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Julia">with_train = vcat(accuracy_train)<br>with_test = vcat(accuracy_test)<br><br>x = range(<span class="hljs-number">1</span>,length(with_train),step=<span class="hljs-number">1</span>)<br>data = [with_train with_test]<br>labels = [<span class="hljs-string">&quot;accuracy_train&quot;</span> <span class="hljs-string">&quot;accuracy_test&quot;</span>]<br>markercolors = [<br>    :red :blue<br>]<br><br>pl_drop=plot(<br>    x,<br>    data,<br>    label = labels,<br>    color = markercolors,<br>    markersize = <span class="hljs-number">4</span>,<br>    title = <span class="hljs-string">&quot;Accuracy with Dropout&quot;</span><br>)<br></code></pre></td></tr></table></figure>
<p>결과는 다음과 같다.</p>
<figure>
<img src="/images/64.png" srcset="/img/loading.gif" lazyload alt="드랍아웃 있음" /><figcaption aria-hidden="true">드랍아웃 있음</figcaption>
</figure>
<p>훈련데이터의 정확도와 실제데이터의 정확도 간격이 드랍아웃을 적용하지 않은 모델보다 훨씬 줄어든 것을 확인할 수 있다.</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/machinelearning/" class="category-chain-item">MachineLearning</a>
  
  
    <span>></span>
    
  <a href="/categories/machinelearning/deeplearning/" class="category-chain-item">deeplearning</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/" class="print-no-link">#딥러닝</a>
      
        <a href="/tags/deeplearning/" class="print-no-link">#Deeplearning</a>
      
        <a href="/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/" class="print-no-link">#머신러닝</a>
      
        <a href="/tags/%EC%A4%84%EB%A6%AC%EC%95%84/" class="print-no-link">#줄리아</a>
      
        <a href="/tags/%EC%8B%A0%EA%B2%BD%EB%A7%9D/" class="print-no-link">#신경망</a>
      
        <a href="/tags/dropout/" class="print-no-link">#Dropout</a>
      
        <a href="/tags/%EB%93%9C%EB%9E%8D%EC%95%84%EC%9B%83/" class="print-no-link">#드랍아웃</a>
      
        <a href="/tags/mlp/" class="print-no-link">#MLP</a>
      
        <a href="/tags/%EB%89%B4%EB%9F%B4%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/" class="print-no-link">#뉴럴네트워크</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>[Deep Learning in Julia] 인공신경망 최적화: 드랍아웃 (13/18)</div>
      <div>https://dev-bearabbit.github.io/ko/DeeplearningJulia/Deeplearning-13/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Jess</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>2020년 6월 14일</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/ko/DeeplearningJulia/Deeplearning-14/" title="[Deep Learning in Julia] CNN 시작하기 (14/18)">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">[Deep Learning in Julia] CNN 시작하기 (14/18)</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/ko/DeeplearningJulia/Deeplearning-12/" title="[Deep Learning in Julia] 인공신경망 최적화: 가중치 초기값 (12/18)">
                        <span class="hidden-mobile">[Deep Learning in Julia] 인공신경망 최적화: 가중치 초기값 (12/18)</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://dev-bearabbit.github.io" target="_blank" rel="nofollow noopener"><span>Jess</span></a>
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
